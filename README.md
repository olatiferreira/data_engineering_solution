# Solu√ß√£o para Atualiza√ß√£o dos Dados de Forma Resiliente e Est√°vel üöÄ

## Objetivo üéØ

Tornar o processo de atualiza√ß√£o dos dados atrav√©s das camadas (bronze, silver e gold) mais resilientes e est√°vel, garantindo os SLAs necess√°rios para o neg√≥cio, prevenindo a introdu√ß√£o de m√°s pr√°ticas e erros em produ√ß√£o, sejam de implementa√ß√£o ou de configura√ß√£o. Em caso de detec√ß√£o de problemas, o desenvolvedor deve ser notificado e orientado sobre como proceder. 

## Tecnologias e Ferramentas üíª

- **Armazenamento:** [AWS S3](https://aws.amazon.com/pt/s3/)
- **Processamento:** [Databricks](https://www.databricks.com/br)
- **An√°lise:** [ThoughtSpot](https://www.thoughtspot.com/)
- **Orquestra√ß√£o:** [Airflow](https://airflow.apache.org/)
- **Versionamento e Pipeline CI/CD:** [GitLab](https://about.gitlab.com/)

## [Entreg√°vel 1] - Solu√ß√£o detalhada

### Etapas üìÉ

#### 1. Armazenamento

- Para prover escalabilidade e durabilidade dos dados, eles ser√£o armazenados em camadas no AWS S3, conforme abaixo:

    - **Bronze:** Dados brutos na forma original.
    - **Silver:** Dados transformados.
    - **Gold:** Dados validados e prontos para an√°lise e uso pelas unidades de neg√≥cio, utilizando o ThoughtSpot por exemplo.

- Os metadados dos dados (fonte, data, schema, etc.) poder√£o ser armazenados em um banco de dados NoSQL, como por exemplo o DynamoDB, facilitando a consulta, gerenciamento e governan√ßa;

- Para reduzir custos e otimizar o armazenamento, ser√£o implementadas pol√≠ticas de ciclo de vida dos dados, as quais ir√£o permitir automatizar a transi√ß√£o dos dados entre diferentes classes de armazenamento do S3 com base nos padr√µes de acesso;

    -  Por exemplo, os dados que n√£o forem acessados ap√≥s um determinado per√≠odo de tempo ser√£o  movidos para a classe de armazenamento S3 Infrequent Access (S3 IA) ou at√© mesmo para a S3 Glacier Flexible Retrieval.

#### 2. Processamento

- O Databricks ser√° utilizado como plataforma de processamento de dados em nuvem, que al√©m de prover recursos de clusteriza√ß√£o, tamb√©m ir√° oferecer provisionamento autom√°tico para lidar com grandes volumes de dados para executar as tarefas de ETL (extra√ß√£o, transforma√ß√£o e carregamento), limpeza e prepara√ß√£o dos dados, o que significa que recursos poder√£o ser dimensionados de acordo com a demanda, reduzindo significativamente os custos operacionais;

    - Por exemplo, poder√° ser provisionado clusters tempor√°rios para execu√ß√£o de tarefas apenas quando necess√°rio, evitando gastos excessivos com infraestrutura ociosa;

- Cada notebook ser√° executado em um cluster Databricks dedicado, conforme as boas pr√°ticas recomendam, aproveitando a escalabilidade e o poder de processamento da plataforma de forma eficiente, garantindo que apenas os recursos necess√°rios sejam utiliados;

    - Por exemplo, poder√° ser configurado pol√≠ticas de auto-escalonamento para ajustar dinamicamente o tamanho dos clusters com base na carga de trabalho, evitando desperd√≠cio de recursos e consequentemente reduzindo os custos.

#### 3. An√°lise

- O ThoughtSpot ser√° utilizado como plataforma de an√°lise de dados self-service, fornecendo aos usu√°rios de neg√≥cio acesso interativo e visual aos dados da camada gold;

- Os usu√°rios poder√£o explorar os dados, criar dashboards e relat√≥rios personalizados, sem a necessidade de conhecimento t√©cnico aprofundado.

#### 4. Orquestra√ß√£o

- O Airflow ser√° utilizado para agendar, monitorar e gerenciar os pipelines de dados;

- Pol√≠ticas de escalonamento din√¢mico de recursos ser√£o configuradas para aumentar ou diminuir o n√∫mero de workers do Airflow com base na carga de trabalho, otimizando os recursos de computa√ß√£o, reduzindo significamente os custos;

- Ser√° implementado scripts e ferramentas que desligam automaticamente inst√¢ncias do Airflow quando n√£o estiverem em uso por um determinado per√≠odo de tempo;

- Alertas ser√£o configurados e poder√£o ser enviados no Slack, notificando o desenvolvedor sobre as m√©tricas de desempenho dos pipelines (tempo de execu√ß√£o, volume de dados processados, taxa de erros, etc) e sobre o status de execu√ß√£o das etapas dos pipelines, incluindo falhas;

- Todos os logs ser√£o armazenados no S3 para fins an√°lise e investiga√ß√£o, possibilitando a identifica√ß√£o de oportunidades de otimiza√ß√£o e ajustes nas configura√ß√µes para reduzir custos sem comprometer a disponibilidade.

#### 5. Versionamento e Pipeline CI/CD

- O GitLab ser√° utilizado como reposit√≥rio para gerenciamento, controle de vers√£o e documenta√ß√£o dos scripts, integra√ß√£o cont√≠nua, entrega cont√≠nua e colabora√ß√£o entre equipes de desenvolvimento;

- Ser√° configurado um pipeline que ir√° executar testes automatizados, como testes unit√°rios e testes de integra√ß√£o, sempre que houver uma nova altera√ß√£o no c√≥digo do reposit√≥rio;

- Haver√° a implementa√ß√£o de um processo de revis√£o de c√≥digo, onde os membros da equipe revisam e validam as altera√ß√µes propostas antes de serem integradas ao pipeline principal;

- Ferramentas de linting e verificadores de estilo de c√≥digo ser√£o utilizadas para garantir que o c√≥digo do pipeline siga as melhores pr√°ticas e os padr√µes estabelecidos;

- Ferramentas de an√°lise est√°tica de c√≥digo ser√£o configuradas para identificar potenciais problemas de qualidade, como c√≥digo duplicado, complexidade excessiva e vulnerabilidades de seguran√ßa.

#### 6. Governan√ßa de Dados

- Um cat√°logo de dados ser√° implementado para documentar as fontes de dados, pipelines, tabelas e outros artefatos relacionados √† gest√£o de dados;

- Pol√≠ticas de acesso, qualidade e seguran√ßa ser√£o definidas e aplicadas para restringir e controlar o acesso aos dados, garantindo a confiabilidade, confidencialidade e integridade dos dados.

### Trade-offs üîÑ

- **Custo:** A utiliza√ß√£o de ferramentas como Databricks e ThoughtSpot poder√£o gerar custos adicionais. No entanto, o retorno do investimento (ROI) da solu√ß√£o poder√° ser significativo em termos de maior efici√™ncia, produtividade e redu√ß√£o de riscos.

- **Escalabilidade e Elasticidade:** A configura√ß√£o correta dos recursos de escalabilidade e elasticidade pode ser complexa. No entanto, uma vez configurados adequadamente, esses recursos permitem que os pipelines de dados se adaptem dinamicamente √† demanda, garantindo um desempenho consistente mesmo diante de varia√ß√µes na carga de trabalho.

- **Servi√ßos Gerenciados:** A solu√ß√£o depende da disponibilidade e desempenho de servi√ßos gerenciados como AWS S3, Databricks e ThoughtSpot. No entanto, permitir√° que a equipe se concentre nas tarefas de valor agregado, aproveitando a expertise e a infraestrutura desses provedores, o que pode resultar em uma implementa√ß√£o mais r√°pida e eficiente dos pipelines de dados.

- **Complexidade:** A implementa√ß√£o da solu√ß√£o completa poder√° exigir um investimento inicial em treinamento e familiariza√ß√£o das equipes com as novas ferramentas. No entanto, a longo prazo, a solu√ß√£o ir√° contribuir para a padroniza√ß√£o dos processos, reduzindo o tempo de desenvolvimento e a necessidade de manuten√ß√£o dos pipelines.

### Benef√≠cios üéÅ

- **Armazenamento centralizado e seguro de dados:** O S3 garante que seus dados estejam sempre dispon√≠veis e protegidos.

- **Efici√™ncia operacional:** O Databricks permite lidar com grandes volumes de dados de forma eficiente e escal√°vel, otimizando recursos e reduzindo custos operacionais.

- **An√°lise de dados self-service:** O ThoughtSpot capacita os usu√°rios de neg√≥cios a explorar e analisar dados sem a necessidade de conhecimento t√©cnico aprofundado.

- **Automa√ß√£o e orquestra√ß√£o:** O Airflow garante que o pipeline de dados seja executado de forma confi√°vel e consistente, garantindo os SLAs necess√°rios para o neg√≥cio.

- **Controle de vers√£o e qualidade do c√≥digo:** Al√©m do GitLab realizar o  controle de vers√£o e documenta√ß√£o dos scripts, garantindo a colabora√ß√£o entre equipes de desenvolvimento, tamb√©m implementa pipelines CI/CD automatizados, que juntamente com testes automatizados e de revis√£o de c√≥digo, assegura a qualidade do c√≥digo e a integridade dos pipelines.

## Desenvolvido por ‚ú®

- [√çtalo C√©sar Ferreira da Costa](https://www.olatiferreira.com)